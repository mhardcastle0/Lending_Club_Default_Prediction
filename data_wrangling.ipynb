{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The purpose of this project is to evaluate how well macroeconomic factors at the time that a loan is originated predict\n",
    "the loan's default likelihood. The below reads in a dataset of Lending Club loan data, including loan default statistics\n",
    "and origination dates. It additionally reads in a dataset containing monthly data on the number of bankruptcies filed\n",
    "nationally by month, stock market data, and unemployment data. Finally, the data sources are all combined for future analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the relevant libraries. In addition to Pandas, a library designed to connect to the FRED\n",
    "# (Federal Reserve Economic Data) API is used.\n",
    "\n",
    "import pandas as pd\n",
    "import fredapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the Lending Club accepted loan dataset into a Pandas dataframe. The file\n",
    "# was sourced from the following:\n",
    "# https://www.kaggle.com/wordsforthewise/lending-club\n",
    "\n",
    "local_directory = r'C:\\Users\\Mark\\Desktop\\springboard_projects\\data'\n",
    "lending_club_data = pd.read_csv(local_directory + r'\\lending_club_accepted_loans.csv')\n",
    "\n",
    "# The issue date needs to be converted from \"mmm-yyyy\" to the first of the month, to conform to the other data sources\n",
    "lending_club_data['orig_month'] = pd.to_datetime('01-' + lending_club_data['issue_d'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the monthly bankruptcy dataset into a Pandas dataframe. The file was\n",
    "# sourced from the following:\n",
    "# https://www.abi.org/newsroom/epiq-stats/april-2019-bankruptcy-statistics-state-and-district\n",
    "local_directory = r'C:\\Users\\Mark\\Desktop\\springboard_projects\\data'\n",
    "bankruptcy_data = pd.read_excel(f'{local_directory}\\\\monthly_bk_data.xlsx', sheet_name='Filings by Jurisdiction',\n",
    "                               header=None, skiprows=1, index_col=0)\n",
    "\n",
    "# The original file has merged cells across the top representing years, and a \"TOTAL\" row across the bottom.\n",
    "# The years need to extend throughout the merged cells, the years/months merged into a single index, all but the TOTAL\n",
    "# rows removed, and the data rotated.\n",
    "\n",
    "# Subset to only the year, month, and \"TOTAL\" rows. First, change the first two row names to \"year\" and \"month\"\n",
    "new_index = bankruptcy_data.index.tolist()\n",
    "new_index[0] = 'year'\n",
    "new_index[1] = 'month'\n",
    "bankruptcy_data.index = new_index\n",
    "\n",
    "# Then, subset the df to only the year, month, and TOTAL\n",
    "\n",
    "bk_data_subset = bankruptcy_data.loc[['year', 'month', 'TOTAL']]\n",
    "\n",
    "# The 'year' row was the row of merged cells. The row must be forward-filled to replace NaN values with\n",
    "# the correct years.\n",
    "\n",
    "bk_data_subset.loc['year'] = bk_data_subset.loc['year'].fillna(method='ffill')\n",
    "\n",
    "# Transpose the data\n",
    "bk_data_subset = bk_data_subset.T\n",
    "\n",
    "# Combine the year and month into a single column, which will be used as the date column\n",
    "bk_data_subset['bk_month'] = bk_data_subset['month'] + ' 1 ' + bk_data_subset['year'].map(str)\n",
    "\n",
    "# Convert the bk_month column to datetime.\n",
    "bk_data_subset['bk_month'] = pd.to_datetime(bk_data_subset['bk_month'], format='%B %d %Y', errors='coerce')\n",
    "\n",
    "# There are some rows that do not contain month-year-TOTAL data. Anything that is not a datetime in bk_month\n",
    "# is one of these rows and is removed.\n",
    "bk_data_subset = bk_data_subset.loc[~bk_data_subset['bk_month'].isnull()]\n",
    "\n",
    "# The rows with zero total bankruptcies represent months that have not yet passed. They can be removed.\n",
    "bk_data_subset = bk_data_subset.loc[bk_data_subset['TOTAL'] != 0]\n",
    "\n",
    "# The dataframe can now be indexed using the bk_month column, have the 'year' and 'month' columns removed,\n",
    "# and be sorted by the new index.\n",
    "bk_data_subset = bk_data_subset[['TOTAL', 'bk_month']]\n",
    "bk_data_subset.columns = ['monthly_bks', 'month']\n",
    "bk_data_subset = bk_data_subset.set_index('month').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_data_subset.head()\n",
    "bk_data_subset.to_pickle(r'C:\\Users\\Mark\\Desktop\\springboard_projects\\data\\monthly_bk_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bad Request.  The value for variable api_key is not a 32 character alpha-numeric lower-case string.  Read https://research.stlouisfed.org/docs/api/api_key.html for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fredapi\\fred.py\u001b[0m in \u001b[0;36m__fetch_data\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-abd2d0945a4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Pull the S&P 500 data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msp_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SP500'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0msp_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fredapi\\fred.py\u001b[0m in \u001b[0;36mget_series\u001b[1;34m(self, series_id, observation_start, observation_end, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'&'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__fetch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No data exists for series id: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mseries_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fredapi\\fred.py\u001b[0m in \u001b[0;36m__fetch_data\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Bad Request.  The value for variable api_key is not a 32 character alpha-numeric lower-case string.  Read https://research.stlouisfed.org/docs/api/api_key.html for more information."
     ]
    }
   ],
   "source": [
    "# The remainder of the data is sourced from the FRED API below. The unemployment data is formatted ideally for \n",
    "\n",
    "# Set up the API. The API key is removed from the published version.\n",
    "API_KEY = ''\n",
    "fred = fredapi.Fred(api_key=API_KEY)\n",
    "\n",
    "# Pull the S&P 500 data\n",
    "sp_data = fred.get_series('SP500').to_frame().reset_index()\n",
    "sp_data.columns = ['date', 'value']\n",
    "\n",
    "# There is no S&P data on some weekend/holiday days. To accommodate this, the data is forward filled.\n",
    "\n",
    "# The data needs to be converted to a format that is usable at the monthly level. It will be summarized to\n",
    "# only the close price on the first and last day of the month.\n",
    "modified_sp = pd.DataFrame(index=sp_data['date'])\n",
    "sp_data['bom'] = sp_data['date'].values.astype('<M8[M]')\n",
    "sp_data['eom'] = pd.Index(sp_data['bom']).to_period('M').to_timestamp('M')\n",
    "\n",
    "bom_values = sp_data[sp_data['bom'] == sp_data['date']][['date', 'value']]\n",
    "eom_values = sp_data[sp_data['eom'] == sp_data['date']][['date', 'value']]\n",
    "eom_values['date'] = eom_values['date'].values.astype('<M8[M]')\n",
    "\n",
    "bom_values.columns = ['date', 'bom_value']\n",
    "eom_values.columns = ['date', 'eom_value']\n",
    "\n",
    "modified_sp = modified_sp.merge(right=bom_values, how='left', left_index=True, right_on='date')\n",
    "modified_sp = modified_sp.merge(right=eom_values, how='left', left_on='date', right_on='date')\n",
    "\n",
    "modified_sp = modified_sp.loc[~modified_sp['bom_value'].isnull()]\n",
    "\n",
    "# There is no S&P data on some weekend/holiday days. To accommodate this, the data is forward filled.\n",
    "modified_sp['bom_value'] = modified_sp['bom_value'].fillna(method='ffill')\n",
    "modified_sp['eom_value'] = modified_sp['eom_value'].fillna(method='ffill')\n",
    "\n",
    "# The average monthly stock price may be a better indicator for stock market performance than BOM or EOM\n",
    "# values. Average monthly stock prices are pulled in as well.\n",
    "bom_mean = sp_data[['bom', 'value']].groupby('bom').mean()\n",
    "modified_sp = modified_sp.merge(bom_mean, left_on='date', right_index=True)\n",
    "modified_sp = modified_sp.rename(columns={'value': 'month_avg'})\n",
    "\n",
    "# Pull the unemployment data\n",
    "unemployment_data = fred.get_series('UNRATE').to_frame()\n",
    "unemployment_data.columns = ['unemployment_rate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purposes of this analysis, daily stock market volatility introduces noise which may\n",
    "# obscure the true relationships between stock trends and default likelihood. In addition,\n",
    "# the bankruptcy, origination, and unemployment data are only available at the monthly level.\n",
    "# For these reasons, all data is sampled at the monthly level before being combined.\n",
    "\n",
    "# Merge the unemployment data into the Lending Club data\n",
    "combined_data = lending_club_data.merge(right=unemployment_data, left_on='orig_month', right_index=True)\n",
    "\n",
    "# Merge the S&P 500 data into the combined dataset\n",
    "combined_data = combined_data.merge(right=modified_sp, left_on='orig_month', right_on='date')\n",
    "\n",
    "# Merge the BK data into the combined dataset\n",
    "combined_data = combined_data.merge(right=bk_data_subset, left_on='orig_month', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data to make certain that all works as intended\n",
    "print(combined_data.info(verbose=True))\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
